-- Flink

https://github.com/confluentinc/tutorials/tree/master/aggregating-count/flinksql

https://github.com/confluentinc/tutorials/blob/36e9deeda90819371a593964395deff613fa222d/docker/docker-compose-flinksql.yml

-- A all in one CP stack, confluent broker, connect, schema,ksqldb, CC & flink etc.
https://github.com/confluentinc/cp-all-in-one/blob/08214d200c21d0b7382fca4e01d9900945a51498/cp-all-in-one-flink/docker-compose.yml

-- error atm, no data
docker exec -t kafkacat \
  kcat \
  -b broker:29092 \
  -t movie-ticket-sales \
  -C -J \
  |jq 

  docker exec -t kafkacat \
  kcat \
  -b broker:29092 \
  -t movie-ticket-sales \
  -C -J \
  |jq '.payload'

CREATE TABLE movie_ticket_sales (
    title STRING,
    sales_ts STRING,
    total_ticket_value INT
) WITH (
    'connector' = 'kafka',
    'topic' = 'movie-ticket-sales',
    'properties.bootstrap.servers' = 'broker:29092',
    'scan.startup.mode' = 'earliest-offset',
    'key.format' = 'raw',
    'key.fields' = 'title',
    'value.format' = 'avro-confluent',
    'value.avro-confluent.url' = 'http://schema-registry:8081',
    'value.fields-include' = 'EXCEPT_KEY'
);

INSERT INTO movie_ticket_sales VALUES
    ('Aliens', '2019-07-18T10:00:00Z', 10),
    ('Die Hard', '2019-07-18T10:00:00Z', 12),
    ('Die Hard', '2019-07-18T10:01:00Z', 12),
    ('The Godfather', '2019-07-18T10:01:31Z', 12),
    ('Die Hard', '2019-07-18T10:01:36Z', 24),
    ('The Godfather', '2019-07-18T10:02:00Z', 18),
    ('The Big Lebowski', '2019-07-18T11:03:21Z', 12),
    ('The Big Lebowski', '2019-07-18T11:03:50Z', 12),
    ('The Godfather', '2019-07-18T11:40:00Z', 36),
    ('The Godfather', '2019-07-18T11:40:09Z', 18);
    
    
SELECT title,
       COUNT(total_ticket_value) AS tickets_sold
FROM movie_ticket_sales
GROUP BY title;