-- MongoAtlas
use admin
db.createUser(
  {
    user: "admin",
    pwd: "abfr24", // or cleartext password
    roles: [ { role: "root", db: "admin" }, "readWriteAnyDatabase" ]
  }
)

db.createUser(
  {
    user: "go_etl_app",
    pwd: "FAVOm5MEj963jA4j", // or cleartext password
    roles: [ { role: "userAdminAnyDatabase", db: "admin" }, "readWriteAnyDatabase" ]
  }
)


// or cleartext password

db.auth("admin", passwordPrompt()) 

db.adminCommand( { shutdown: 1 } )

-- local sink
curl -X POST \
     -H "Content-Type: application/json" \
     --data '
     {"name": "mongo-sink",
      "config": {
         "connector.class":"com.mongodb.kafka.connect.MongoSinkConnector",
         "connection.uri":"mongodb://mbp.local:27017/?directConnection=true",
         "database":"quickstart",
         "collection":"topicData",
         "topics":"quickstart.sampleData",
         "change.data.capture.handler": "com.mongodb.kafka.connect.sink.cdc.mongodb.ChangeStreamHandler"
         }
     }
     ' \
     http://127.0.0.1:8083/connectors -w "\n"
     


mongosh mongodb://localhost:27017/?directConnection=true

use quickstart

db.topicData.insertOne({"hello":"world"})


-- local Source
curl -X POST \
     -H "Content-Type: application/json" \
     --data '
     {"name": "mongo-source",
      "config": {
         "connector.class":"com.mongodb.kafka.connect.MongoSourceConnector",
         "connection.uri":"mongodb://mbp.local:27017/?directConnection=true",
         "database":"quickstart",
         "collection":"InputData",
         "pipeline":"[{\"$match\": {\"operationType\": \"insert\"}}, {$addFields : {\"fullDocument.travel\":\"MongoDB Kafka Connector\"}}]"
         }
     }
     ' \
     http://127.0.0.1:8083/connectors -w "\n"


-- shell:
mongosh "mongodb+srv://cluster0.gqtneeXX.mongodb.net/" --apiVersion 1 --username adminuser


Modifying Confluent Connector logging Levels
https://docs.confluent.io/platform/current/connect/logging.html


kcat -b localhost:9092 -t quickstart.sampleData

-- Installing Mongo connector plugin into containerised CP Kafka
https://www.youtube.com/watch?v=18gDPSOH3wU

-- after adding.modifying Dockerfile - adding a plugin, redeploy using below.
-- docker compose up -d --build


curl -s "http://mbp.local:8083/connectors?expand=info&expand=status" | \
       jq '. | to_entries[] | [ .value.info.type, .key, .value.status.connector.state,.value.status.tasks[].state,.value.info.config."connector.class"]|join(":|:")' | \
       column -s : -t| sed 's/\"//g'| sort

